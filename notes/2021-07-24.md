# 2021-07-24
I need to rethink how the batch processing works - do some refactoring and turn it inside out.
At the moment it loops through the batches and trains on each batch for N generation.  This means it will be trained to a small subset of the data, before moving on to the next.  I did it that to keep the function generic. Instead I want to have the outer loop over the generations and the inner loop over the batches.   To do that I will have to have to make the function more specific, or make it optional. 
I think for reinforcement learning I will need a different GP engine anyway.

... hmmm.. I have made the change, but if anything the accuracy is worse.  Also there is a log delay between printing slice 0 and slice 1, so I may have introduced a bug.
I tried changing use stratified kfold but it makes no difference to the accuracy.  It still doesn't go much above 0.45 and worse on the test set.
Duh... I left the select/mate/mutate bit out of the inner loop - it was only updating the replacements.
Fixing that gets a similar accuracy as no batching  8^(
Took 24m 29s for 5 folds with best test accuracy of 0.59.
Time to re-enable tensorboard and run it again.  Then I can do some tuning of hyperparameters.
