# 2021-07-25
I need to think about hyperparameter tuning...
What can I do to improve accuracy?
- increase number of generations
- increase population
- make pruning configurable?
- profile the code and see if there is opportunity for speeding up
    - may need rewriting in cython/numba etc.
    - find proportion of time spent in deap and proportion in skfuzzy
- use a smaller batch size than 100 - maybe 20?
- reduce the number of consequents, or make them random

I also need to think about how to manage the hyperparameters - control values and record the results in a way that I can easily incorporate into the report. 
Also start sketching out the report in note format.  

Strange... with a batch size of 10 it reports a training accuracy of 0.9 then a much lower test accuracy.  Maybe because the training accuracy is only on the last mini-batch?
I think it is because of the HOF - if one member does well on a small subset of data then it will go to the top of the HOF and never change or get re-evaluated.  Maybe if we are doing batches we should re-evaluate them on every batch.  Or use bigger batches.
Thoughts:
- Re-evaluate all the members and rebuild the HOF for each batch.
