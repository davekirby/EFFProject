# 2021-07-15
Carrying on with the code to prune trees...

ToDo (recap):
- add more tests
- add code to run it on a ruleset & a population
    - run every time create or modify an individual
- generate a population and see what effect it has on the sizes.  How much does it really save?  How long does it take?
- see what effect it has on speed and convergence

The thought occurred to me today that I don't know what happens if you compare terminals or ephemerals - does it take into account different values?  I need to check that...

It looks like it should be OK - the terminal class implements the `__eq__` method that should do the right thing.
Also at the moment I only use ephemerals for the consequent.  
The only terminals are the antecendents, so will add an explicit test for that.

I have got pruning the population working - I prune just before evaluating the subpopulation with no fitness, so I know I always prune each rule once.

For small trees like I have for iris data set it does not remove much - only occasionally a couple per population each generation.  When I increase the tree size though it did make a big different - removing 20-40 primitives per generation, so I will leave it in.


I have started looking for a suitable dataset for evaluation and tuning.
Some resources:
https://machinelearningmastery.com/standard-machine-learning-datasets/
https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research
https://www.openml.org/home (loadable directly in sklearn)
https://machinelearningmastery.com/results-for-standard-classification-and-regression-machine-learning-datasets/
https://archive.ics.uci.edu/ml/index.php



