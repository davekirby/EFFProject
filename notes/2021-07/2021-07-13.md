# 2021-07-13
What to do today?
I have set the HOF size to 10 to see what effect it has - seems to converge slightly faster.  Not sure if it makes it more likely to get stuck in a local optima though.  

To do:
- change optimising error to optimise accuracy (min -> max)
    - make the metric configurable?
    - having large = good is consistent with sklearn - will make it easier to plug in different metrics
- implement rule pruning
- implement minibatch

Strange... I have changed the fitness to use the accuracy and min to max, but it still tries to display the min fitness instead of the max.  The max is being sent to tensorboard though.  What gives?
Ah found it - the headers are set up when the logbook is created.  

